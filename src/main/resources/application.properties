quarkus.langchain4j.ollama.chat-model.model-id=tinyllama
quarkus.langchain4j.ollama.wiseModel.chat-model.model-id=tinydolphin
quarkus.langchain4j.ollama.curiousModel.chat-model.model-id=tinyllama

# In MacOS the DevServices with Ollama is not working and we need to have Ollama running in the background
quarkus.langchain4j.ollama.devservices.model=tinyllama
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.timeout=60s

quarkus.fx.fxml-root=/fxml/
quarkus.package.jar.type=uber-jar